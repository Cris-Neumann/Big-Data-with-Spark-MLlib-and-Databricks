<h1 align="center"> Big Data con Spark MLlib y Databricks </h1>

## √çndice

- [Resumen del proyecto](#Resumen-del-proyecto)
- [¬øQu√© es Databricks?](#qu√©-es-databricks)
- [¬øQu√© es Kaggle?](#qu√©-es-kaggle)
- [Arquitectura empleada](#Arquitectura-empleada)
- [Sobre el conjunto de datos](#Sobre-el-conjunto-de-datos)
- [Sobre la m√©trica de evaluaci√≥n](#Sobre-la-m√©trica-de-evaluaci√≥n)
- [Proceso de creaci√≥n del modelo de ML](#Proceso-de-Creaci√≥n-del-Modelo-de-ML)

## Resumen del proyecto
El siguiente proyecto tiene como objetivo predecir la probabilidad de que un cliente no pague el saldo de su tarjeta de cr√©dito en el futuro, en funci√≥n de su perfil de cliente mensual. Para ello, se procesar√°n archivos con millones de registros de transacciones bancarias anonimizadas de American Express, obtenidos desde Kaggle (ver: https://acortar.link/LOfyfq).

La capacidad de c√≥mputo necesaria para ejecutar varias operaciones sobre estas cantidades de datos (y sobre todo para cantidades mayores) suele sobrepasar la capacidad de una sola m√°quina. Por esta raz√≥n, se utilizar√° la plataforma Databricks, que facilita el uso de Apache Spark para estos fines y tiene la capacidad para realizar c√≥mputos de forma distribuida, es decir, utilizar varias m√°quinas en paralelo para aumentar la capacidad de procesamiento. Dado que se utilizar√° la versi√≥n Community Edition, que es gratuita, s√≥lo podremos acceder a un solo nodo de c√≥mputo, por lo que para utilizar computaci√≥n distribuida, se debe acceder a versiones pagadas.

Para cumplir el objetivo de predicci√≥n, se usar√° un algoritmo de Machine Learning llamado Gradient Boosting Trees (GBTClassifier) con el fin de predecir el incumplimiento crediticio. En el proceso de obtenci√≥n de datos, se utilizar√° la API de Kaggle y un bucket de Amazon S3. Los resultados (inferencia, datasets depurados y modelo de ML utilizado) ser√°n almacenados en un bucket de S3. Todos los c√≥digos ser√°n almacenados en archivos con extensi√≥n .ipynb (Jupyter Notebook), pues Databricks permite exportar y cargar sus notebooks en este formato y en .dbc, pero dado que no todos los usuarios podr√°n leer los archivos .dbc, el formato .ipynb es una mejor opci√≥n para que cualquier persona pueda leer los notebooks en sus IDE (entorno de desarrollo integrado) favoritos, como Visual Studio Code por ejemplo.

## ¬øQu√© es Databricks?
Databricks es una plataforma en la nube que optimiza el uso de Apache Spark para la ingenier√≠a de datos. Facilita la colaboraci√≥n entre ingenieros de datos y cient√≠ficos de datos al proporcionar un entorno integrado para el procesamiento y an√°lisis de grandes vol√∫menes de datos. Permite dise√±ar, implementar y gestionar flujos de trabajo de datos de manera eficiente, aprovechando las capacidades de Apache Spark para realizar tareas de ETL, procesamiento en tiempo real y Machine Learning.. Documentaci√≥n oficial: https://www.databricks.com/databricks-documentation.

* Es importante notar que, para aplicaciones creadas con Apache Spark, en Databricks no es necesario inicializar el "SparkContext" ni crear "SparkSessions", ya que el entorno lo hace autom√°ticamente.
  
* Como paso previo, se debe crear un cl√∫ster. En la versi√≥n Community Edition, el cl√∫ster tiene 15 GB de memoria y 2 n√∫cleos. Adjunto una imagen donde se muestra c√≥mo crear el cl√∫ster en la secci√≥n "Compute":

<p align="center">
  <img width="555" alt="create_test_cluster" src="https://github.com/user-attachments/assets/58557b47-3c53-47cb-b46f-788999920702">
</p>

* Por un lado, cuando se accede al sistema de archivos local en Databricks (por ejemplo, 'file:/tmp/wiki_data/') desde el nodo en el que se est√° ejecutando el c√≥digo, es similar a c√≥mo se manejan archivos en un entorno de escritorio o servidor normal. Los archivos almacenados en el sistema de archivos local son temporales y pueden no estar disponibles despu√©s de que finaliza la sesi√≥n o se reinicia el cl√∫ster.

* Por otro lado, Databricks cuenta con un sistema de archivos distribuido llamado 'DBFS' (Databricks File System) (por ejemplo, 'dbfs:/tmp/wiki_data/'), el cual est√° disponible en todos los nodos del cl√∫ster de Databricks. Esto significa que los archivos en DBFS pueden ser accedidos desde cualquier nodo, lo cual es crucial para la ejecuci√≥n de trabajos distribuidos. Los archivos almacenados en DBFS son persistentes y permanecen disponibles incluso despu√©s de que finaliza la sesi√≥n o se reinicia el cl√∫ster. Esto hace que DBFS sea ideal para almacenar datos que necesitas reutilizar o compartir entre sesiones. Adem√°s, DBFS est√° optimizado para trabajar con Apache Spark, lo que facilita la lectura y escritura de grandes conjuntos de datos distribuidos.

## ¬øQu√© es Kaggle?
Kaggle es una plataforma en l√≠nea para competencias en ciencia de datos, donde los usuarios pueden compartir datos, c√≥digos y modelos, as√≠ como participar en competencias para resolver problemas reales. Para este proyecto, es necesario crear una cuenta gratuita en Kaggle ( https://www.kaggle.com/ ) y utilizar su API p√∫blica. Para ello, debes solicitar la creaci√≥n de tu API Token en su p√°gina web (ver totorial al respecto: https://christianjmills.com/posts/kaggle-obtain-api-key-tutorial/ ). Esto te proporcionar√° un archivo JSON que contiene tu usuario y la clave de la API de Kaggle.

## Arquitectura empleada
El esquema general del modo en que se relacionan las partes del sistema es el siguiente:
<br/><br/>

![Databricks](https://github.com/user-attachments/assets/0e14303f-4b51-4895-a25e-99814618568d)


## Sobre el conjunto de datos
El conjunto de datos contiene caracter√≠sticas de perfil agregadas para cada cliente (campo "customer_ID") en cada fecha de estado de cuenta. El n√∫mero total de registros supera los 11 millones de operaciones crediticias en el conjunto a predecir, 5.5 millones en el conjunto de entrenamiento, y alrededor de 450.000 clientes etiquetados. Las caracter√≠sticas est√°n anonimizadas, normalizadas y se dividen en las siguientes categor√≠as generales:

- D_* = Variables de morosidad
- S_* = Variables de gasto
- P_* = Variables de pago
- B_* = Variables de equilibrio
- R_* = Variables de riesgo

Con las siguientes caracter√≠sticas siendo categ√≥ricas: ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'] El objetivo es predecir, para cada "customer_ID", la probabilidad de un futuro impago (campo "target" = 1).

## Sobre la m√©trica de evaluaci√≥n
La m√©trica de evaluaci√≥n, ùëÄ, para este proyecto es la media de dos medidas de ordenamiento por rango: Coeficiente de Gini Normalizado, ùê∫, y la tasa de incumplimiento, ùê∑.

ùëÄ = 0,5 ‚ãÖ ( ùê∫ + ùê∑ )

La tasa predeterminada capturada en 4% es el porcentaje de etiquetas positivas (predeterminadas) capturadas dentro del 4% de las predicciones con mayor clasificaci√≥n y representa una estad√≠stica de Sensibilidad/Recuperaci√≥n. Para ambas subm√©tricas ùê∫ y ùê∑, a las etiquetas negativas se les asigna un peso de 20 para ajustar el muestreo descendente. Esta m√©trica tiene un valor m√°ximo de 1.0. Para cada id de cliente del conjunto de prueba (campo 'customer_ID'), se va a predecir la probabilidad para la variable objetivo, en el formato (customer_ID, prediction).

## Proceso de creaci√≥n del modelo de ML
- Ingesta de datos: Los datos de entrenamiento y de los clientes a evaluar se obtendr√°n desde la API de Kaggle, ambos en formato parquet. Mientras que las etiquetas (campo donde se clasifican como clientes con default o no, para realizar aprendizaje supervisado) de los id de clientes han sido almacenadas en Amazon S3, en formato CSV, desde donde Databricks deber√° obtener dichos registros. En archivos "extract_data" y "extract_labels" se muestra como obtener los datos y las etiquetas, respectivamente. Una vez extra√≠dos, ser√°n almacenados de forma transitoria en DBFS.

- An√°lisis Exploratorio de datos (EDA) e Ingenier√≠a de Caracter√≠sticas: Se realiza la exploraci√≥n de los datos, con el fin de conocer su distribuci√≥n, valores faltantes, estructura, volumen y forma de registros y caracter√≠sticas, entre otros. Luego, con la informaci√≥n acumulada, se realiza la ingenier√≠a de caracter√≠sticas, donde se realizan operaciones entre columnas y se seleccionan las que ser√°n parte del dataset final. Una vez determinadas las caracter√≠stics finales, ser√°n almacenadas de forma transitoria en DBFS. En archivo "feature_engineering" se pueden apreciar las operaciones en este paso del proceso. Se adjuntan algunas imagenes de operaciones realizadas para conocer c√≥mo evolucionaron los datos en el tiempo, y c√≥mo se distribuyen las etiquetas en achivo "train_labels.csv"

![eventos](https://github.com/user-attachments/assets/54bf3dd7-3c8c-426f-b516-64fd2f61ef12)

<p align="center">
  <img width="555" alt="create_test_cluster" src="https://github.com/user-attachments/assets/7a6e608e-49e4-40e9-b75d-244e140f1177" alt="distribuciones">
</p>

- Entrenamiento del modelo de ML e Inferencia: Se vectorizan las caracteristicas a utilizar, se selecciona el clasificador Gradient Boosting Trees (GBTClassifier) y se realiza la b√∫squeda de hiperpar√°metros con la t√©cnica de Validaci√≥n Cruzada "K-Fold Cross Validation". Posteriormente se eval√∫a su rendimiento con varias m√©tricas usuales como el Recall, F1 Score y Precision, asi como tambien con la m√©trica particular definida por quien solicita la predicci√≥n, llamada "M score". Finalmente se realiza la inferencia (predicci√≥n) para los clientes solicitados, sobre si caer√°n en dafault o no, guardando esta predicci√≥n como archivo CSV en DBFS y el modelo de ML es almacenado tamb√©n en DBFS. Estas operaciones est√°n en archivo "model_selection".
  
- Peque√±a disgresi√≥n: Gradient Boosting Trees (GBT) es un algoritmo de aprendizaje supervisado utilizado principalmente para tareas de clasificaci√≥n y regresi√≥n. El concepto central detr√°s de GBT es construir un modelo robusto mediante la combinaci√≥n de varios √°rboles de decisi√≥n simples (o d√©biles) de manera secuencial, donde cada √°rbol nuevo intenta corregir los errores cometidos por los √°rboles anteriores. Aunque es computacionalmente intensivo, sus capacidades para manejar datos complejos, su implementaci√≥n nativa en Spark MLlib y su capacidad para producir resultados precisos lo hacen muy popular en el campo del Machine Learning.
  
- Persistencia de datos y modelo: Finalmente, el modelo generado, las predicciones realizadas, y los datasets depurados en el proceso de ingenier√≠a de caracter√≠sticas, son almacenados para que persistan en un bucket de Amazon S3, lo cual se puede apreciar en archivo "save_data". De esta manera, se libera el espacio y memoria de Databricks, y estos resultados pueden ser usados en el futuro por otros usuarios con acceso al bucket.


